[2024-05-01 01:27:47] Captioner(
  (encoder): Encoder(
    (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))
  )
  (decoder): DecoderWithAttention(
    (attention): Attention(
      (encoder_att): Linear(in_features=768, out_features=256, bias=True)
      (decoder_att): Linear(in_features=256, out_features=256, bias=True)
      (full_att): Linear(in_features=256, out_features=1, bias=True)
      (relu): ReLU()
      (softmax): Softmax(dim=1)
    )
    (embedding): Embedding(7708, 300)
    (dropout): Dropout(p=0.5, inplace=False)
    (decode_step): LSTMCell(1068, 256)
    (init_h): Linear(in_features=768, out_features=256, bias=True)
    (init_c): Linear(in_features=768, out_features=256, bias=True)
    (f_beta): Linear(in_features=256, out_features=768, bias=True)
    (sigmoid): Sigmoid()
    (fc): Linear(in_features=256, out_features=7708, bias=True)
  )
)
[2024-05-01 01:29:37] Epoch 1/45, train_loss: 4.002, val_bleu1: 0.559, val_bleu4: 0.114
[2024-05-01 01:31:27] Epoch 2/45, train_loss: 3.282, val_bleu1: 0.601, val_bleu4: 0.149
[2024-05-01 01:33:18] Epoch 3/45, train_loss: 3.048, val_bleu1: 0.600, val_bleu4: 0.165
[2024-05-01 01:35:08] Epoch 4/45, train_loss: 2.902, val_bleu1: 0.638, val_bleu4: 0.190
[2024-05-01 01:36:59] Epoch 5/45, train_loss: 2.786, val_bleu1: 0.554, val_bleu4: 0.150
[2024-05-01 01:38:50] Epoch 6/45, train_loss: 2.689, val_bleu1: 0.669, val_bleu4: 0.208
[2024-05-01 01:40:41] Epoch 7/45, train_loss: 2.615, val_bleu1: 0.640, val_bleu4: 0.187
[2024-05-01 01:42:32] Epoch 8/45, train_loss: 2.552, val_bleu1: 0.578, val_bleu4: 0.164
[2024-05-01 01:44:23] Epoch 9/45, train_loss: 2.495, val_bleu1: 0.652, val_bleu4: 0.202
[2024-05-01 01:46:14] Epoch 10/45, train_loss: 2.448, val_bleu1: 0.617, val_bleu4: 0.184
[2024-05-01 01:48:05] Epoch 11/45, train_loss: 2.398, val_bleu1: 0.647, val_bleu4: 0.201
[2024-05-01 01:49:55] Epoch 12/45, train_loss: 2.350, val_bleu1: 0.660, val_bleu4: 0.209
[2024-05-01 01:51:46] Epoch 13/45, train_loss: 2.317, val_bleu1: 0.608, val_bleu4: 0.179
[2024-05-01 01:53:37] Epoch 14/45, train_loss: 2.279, val_bleu1: 0.619, val_bleu4: 0.190
[2024-05-01 01:55:28] Epoch 15/45, train_loss: 2.239, val_bleu1: 0.678, val_bleu4: 0.224
[2024-05-01 01:57:19] Epoch 16/45, train_loss: 2.218, val_bleu1: 0.671, val_bleu4: 0.213
[2024-05-01 01:59:10] Epoch 17/45, train_loss: 2.169, val_bleu1: 0.624, val_bleu4: 0.191
[2024-05-01 02:01:01] Epoch 18/45, train_loss: 2.152, val_bleu1: 0.657, val_bleu4: 0.204
[2024-05-01 02:02:50] Epoch 19/45, train_loss: 2.123, val_bleu1: 0.657, val_bleu4: 0.212
[2024-05-01 02:04:41] Epoch 20/45, train_loss: 2.095, val_bleu1: 0.668, val_bleu4: 0.210
[2024-05-01 02:06:30] Epoch 21/45, train_loss: 2.077, val_bleu1: 0.659, val_bleu4: 0.212
[2024-05-01 02:08:20] Epoch 22/45, train_loss: 2.057, val_bleu1: 0.684, val_bleu4: 0.230
[2024-05-01 02:10:08] Epoch 23/45, train_loss: 2.031, val_bleu1: 0.675, val_bleu4: 0.219
[2024-05-01 02:11:56] Epoch 24/45, train_loss: 2.006, val_bleu1: 0.659, val_bleu4: 0.213
[2024-05-01 02:13:46] Epoch 25/45, train_loss: 1.992, val_bleu1: 0.661, val_bleu4: 0.213
[2024-05-01 02:15:35] Epoch 26/45, train_loss: 1.955, val_bleu1: 0.665, val_bleu4: 0.217
[2024-05-01 02:17:24] Epoch 27/45, train_loss: 1.944, val_bleu1: 0.660, val_bleu4: 0.213
[2024-05-01 02:19:14] Epoch 28/45, train_loss: 1.939, val_bleu1: 0.660, val_bleu4: 0.222
[2024-05-01 02:21:03] Epoch 29/45, train_loss: 1.913, val_bleu1: 0.651, val_bleu4: 0.209
[2024-05-01 02:22:53] Epoch 30/45, train_loss: 1.877, val_bleu1: 0.668, val_bleu4: 0.220
[2024-05-01 02:24:42] Epoch 31/45, train_loss: 1.885, val_bleu1: 0.661, val_bleu4: 0.209
[2024-05-01 02:26:31] Epoch 32/45, train_loss: 1.864, val_bleu1: 0.659, val_bleu4: 0.215
[2024-05-01 02:28:21] Epoch 33/45, train_loss: 1.850, val_bleu1: 0.656, val_bleu4: 0.206
[2024-05-01 02:30:09] Epoch 34/45, train_loss: 1.817, val_bleu1: 0.658, val_bleu4: 0.207
[2024-05-01 02:31:59] Epoch 35/45, train_loss: 1.824, val_bleu1: 0.658, val_bleu4: 0.218
[2024-05-01 02:33:49] Epoch 36/45, train_loss: 1.799, val_bleu1: 0.668, val_bleu4: 0.211
[2024-05-01 02:35:39] Epoch 37/45, train_loss: 1.789, val_bleu1: 0.657, val_bleu4: 0.211
[2024-05-01 02:37:28] Epoch 38/45, train_loss: 1.759, val_bleu1: 0.670, val_bleu4: 0.212
[2024-05-01 02:39:19] Epoch 39/45, train_loss: 1.769, val_bleu1: 0.643, val_bleu4: 0.196
[2024-05-01 02:41:10] Epoch 40/45, train_loss: 1.764, val_bleu1: 0.670, val_bleu4: 0.216
[2024-05-01 02:43:01] Epoch 41/45, train_loss: 1.750, val_bleu1: 0.662, val_bleu4: 0.219
[2024-05-01 02:44:52] Epoch 42/45, train_loss: 1.748, val_bleu1: 0.665, val_bleu4: 0.217
[2024-05-01 02:46:42] Epoch 43/45, train_loss: 1.737, val_bleu1: 0.671, val_bleu4: 0.217
[2024-05-01 02:48:33] Epoch 44/45, train_loss: 1.711, val_bleu1: 0.639, val_bleu4: 0.203
[2024-05-01 02:50:24] Epoch 45/45, train_loss: 1.718, val_bleu1: 0.642, val_bleu4: 0.203
[2024-05-01 02:51:23] evaluation of the best validation performance model: 
[2024-05-01 02:51:23] train
[2024-05-01 02:51:23] Bleu-1: 0.729
[2024-05-01 02:51:23] Bleu-2: 0.548
[2024-05-01 02:51:23] Bleu-3: 0.410
[2024-05-01 02:51:23] Bleu-4: 0.305
[2024-05-01 02:51:23] 
[2024-05-01 02:51:23] val
[2024-05-01 02:51:23] Bleu-1: 0.684
[2024-05-01 02:51:23] Bleu-2: 0.482
[2024-05-01 02:51:23] Bleu-3: 0.336
[2024-05-01 02:51:23] Bleu-4: 0.230
[2024-05-01 02:51:23] 
[2024-05-01 02:51:23] test
[2024-05-01 02:51:23] Bleu-1: 0.684
[2024-05-01 02:51:23] Bleu-2: 0.482
[2024-05-01 02:51:23] Bleu-3: 0.339
[2024-05-01 02:51:23] Bleu-4: 0.239
[2024-05-01 02:51:23] 
