[2024-05-01 21:02:51] Captioner(
  (encoder): Encoder(
    (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))
  )
  (decoder): DecoderWithAttention(
    (attention): Attention(
      (encoder_att): Linear(in_features=768, out_features=256, bias=True)
      (decoder_att): Linear(in_features=256, out_features=256, bias=True)
      (full_att): Linear(in_features=256, out_features=1, bias=True)
      (relu): ReLU()
      (softmax): Softmax(dim=1)
    )
    (embedding): Embedding(7708, 300)
    (dropout): Dropout(p=0.5, inplace=False)
    (decode_step): LSTMCell(1068, 256)
    (init_h): Linear(in_features=768, out_features=256, bias=True)
    (init_c): Linear(in_features=768, out_features=256, bias=True)
    (f_beta): Linear(in_features=256, out_features=768, bias=True)
    (sigmoid): Sigmoid()
    (fc): Linear(in_features=256, out_features=7708, bias=True)
  )
)
[2024-05-01 21:04:38] Epoch 1/45, train_loss: 4.096, val_bleu1: 0.531, val_bleu4: 0.108
[2024-05-01 21:06:26] Epoch 2/45, train_loss: 3.426, val_bleu1: 0.582, val_bleu4: 0.139
[2024-05-01 21:08:14] Epoch 3/45, train_loss: 3.200, val_bleu1: 0.606, val_bleu4: 0.165
[2024-05-01 21:10:01] Epoch 4/45, train_loss: 3.035, val_bleu1: 0.644, val_bleu4: 0.194
[2024-05-01 21:11:49] Epoch 5/45, train_loss: 2.961, val_bleu1: 0.571, val_bleu4: 0.153
[2024-05-01 21:13:37] Epoch 6/45, train_loss: 2.851, val_bleu1: 0.667, val_bleu4: 0.205
[2024-05-01 21:15:26] Epoch 7/45, train_loss: 2.807, val_bleu1: 0.611, val_bleu4: 0.172
[2024-05-01 21:17:14] Epoch 8/45, train_loss: 2.747, val_bleu1: 0.596, val_bleu4: 0.172
[2024-05-01 21:19:02] Epoch 9/45, train_loss: 2.708, val_bleu1: 0.634, val_bleu4: 0.192
[2024-05-01 21:20:50] Epoch 10/45, train_loss: 2.663, val_bleu1: 0.621, val_bleu4: 0.191
[2024-05-01 21:22:39] Epoch 11/45, train_loss: 2.632, val_bleu1: 0.652, val_bleu4: 0.197
[2024-05-01 21:24:28] Epoch 12/45, train_loss: 2.611, val_bleu1: 0.671, val_bleu4: 0.210
[2024-05-01 21:26:15] Epoch 13/45, train_loss: 2.582, val_bleu1: 0.632, val_bleu4: 0.192
[2024-05-01 21:28:03] Epoch 14/45, train_loss: 2.576, val_bleu1: 0.667, val_bleu4: 0.203
[2024-05-01 21:29:52] Epoch 15/45, train_loss: 2.550, val_bleu1: 0.689, val_bleu4: 0.231
[2024-05-01 21:31:42] Epoch 16/45, train_loss: 2.566, val_bleu1: 0.679, val_bleu4: 0.216
[2024-05-01 21:33:31] Epoch 17/45, train_loss: 2.524, val_bleu1: 0.644, val_bleu4: 0.201
[2024-05-01 21:35:20] Epoch 18/45, train_loss: 2.534, val_bleu1: 0.672, val_bleu4: 0.215
[2024-05-01 21:37:10] Epoch 19/45, train_loss: 2.539, val_bleu1: 0.686, val_bleu4: 0.222
[2024-05-01 21:39:00] Epoch 20/45, train_loss: 2.502, val_bleu1: 0.676, val_bleu4: 0.214
[2024-05-01 21:40:51] Epoch 21/45, train_loss: 2.532, val_bleu1: 0.673, val_bleu4: 0.220
[2024-05-01 21:42:41] Epoch 22/45, train_loss: 2.498, val_bleu1: 0.678, val_bleu4: 0.226
[2024-05-01 21:44:32] Epoch 23/45, train_loss: 2.522, val_bleu1: 0.691, val_bleu4: 0.230
[2024-05-01 21:46:23] Epoch 24/45, train_loss: 2.506, val_bleu1: 0.701, val_bleu4: 0.228
[2024-05-01 21:48:13] Epoch 25/45, train_loss: 2.534, val_bleu1: 0.680, val_bleu4: 0.223
[2024-05-01 21:50:04] Epoch 26/45, train_loss: 2.561, val_bleu1: 0.697, val_bleu4: 0.230
[2024-05-01 21:51:54] Epoch 27/45, train_loss: 2.542, val_bleu1: 0.656, val_bleu4: 0.200
[2024-05-01 21:53:45] Epoch 28/45, train_loss: 2.569, val_bleu1: 0.693, val_bleu4: 0.224
[2024-05-01 21:55:36] Epoch 29/45, train_loss: 2.564, val_bleu1: 0.688, val_bleu4: 0.225
[2024-05-01 21:57:26] Epoch 30/45, train_loss: 2.604, val_bleu1: 0.672, val_bleu4: 0.205
[2024-05-01 21:59:17] Epoch 31/45, train_loss: 2.643, val_bleu1: 0.700, val_bleu4: 0.227
[2024-05-01 22:01:08] Epoch 32/45, train_loss: 2.631, val_bleu1: 0.682, val_bleu4: 0.218
[2024-05-01 22:02:59] Epoch 33/45, train_loss: 2.662, val_bleu1: 0.698, val_bleu4: 0.222
[2024-05-01 22:04:50] Epoch 34/45, train_loss: 2.674, val_bleu1: 0.694, val_bleu4: 0.226
[2024-05-01 22:06:40] Epoch 35/45, train_loss: 2.734, val_bleu1: 0.708, val_bleu4: 0.223
[2024-05-01 22:08:31] Epoch 36/45, train_loss: 2.708, val_bleu1: 0.712, val_bleu4: 0.239
[2024-05-01 22:10:21] Epoch 37/45, train_loss: 2.735, val_bleu1: 0.716, val_bleu4: 0.227
[2024-05-01 22:12:12] Epoch 38/45, train_loss: 2.808, val_bleu1: 0.707, val_bleu4: 0.216
[2024-05-01 22:14:02] Epoch 39/45, train_loss: 2.803, val_bleu1: 0.693, val_bleu4: 0.206
[2024-05-01 22:15:53] Epoch 40/45, train_loss: 2.850, val_bleu1: 0.707, val_bleu4: 0.213
[2024-05-01 22:17:43] Epoch 41/45, train_loss: 2.849, val_bleu1: 0.711, val_bleu4: 0.220
[2024-05-01 22:19:34] Epoch 42/45, train_loss: 2.893, val_bleu1: 0.715, val_bleu4: 0.220
[2024-05-01 22:21:23] Epoch 43/45, train_loss: 2.938, val_bleu1: 0.704, val_bleu4: 0.219
[2024-05-01 22:23:13] Epoch 44/45, train_loss: 2.901, val_bleu1: 0.710, val_bleu4: 0.218
[2024-05-01 22:25:04] Epoch 45/45, train_loss: 3.011, val_bleu1: 0.718, val_bleu4: 0.221
[2024-05-01 22:26:02] evaluation of the best validation performance model: 
[2024-05-01 22:26:02] train
[2024-05-01 22:26:02] Bleu-1: 0.777
[2024-05-01 22:26:02] Bleu-2: 0.599
[2024-05-01 22:26:02] Bleu-3: 0.458
[2024-05-01 22:26:02] Bleu-4: 0.348
[2024-05-01 22:26:02] 
[2024-05-01 22:26:02] val
[2024-05-01 22:26:02] Bleu-1: 0.712
[2024-05-01 22:26:02] Bleu-2: 0.501
[2024-05-01 22:26:02] Bleu-3: 0.347
[2024-05-01 22:26:02] Bleu-4: 0.239
[2024-05-01 22:26:02] 
[2024-05-01 22:26:02] test
[2024-05-01 22:26:02] Bleu-1: 0.702
[2024-05-01 22:26:02] Bleu-2: 0.491
[2024-05-01 22:26:02] Bleu-3: 0.339
[2024-05-01 22:26:02] Bleu-4: 0.234
[2024-05-01 22:26:02] 
