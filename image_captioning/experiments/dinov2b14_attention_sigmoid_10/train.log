[2024-05-01 17:54:36] Captioner(
  (encoder): Encoder(
    (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))
  )
  (decoder): DecoderWithAttention(
    (attention): Attention(
      (encoder_att): Linear(in_features=768, out_features=256, bias=True)
      (decoder_att): Linear(in_features=256, out_features=256, bias=True)
      (full_att): Linear(in_features=256, out_features=1, bias=True)
      (relu): ReLU()
      (softmax): Softmax(dim=1)
    )
    (embedding): Embedding(7708, 300)
    (dropout): Dropout(p=0.5, inplace=False)
    (decode_step): LSTMCell(1068, 256)
    (init_h): Linear(in_features=768, out_features=256, bias=True)
    (init_c): Linear(in_features=768, out_features=256, bias=True)
    (f_beta): Linear(in_features=256, out_features=768, bias=True)
    (sigmoid): Sigmoid()
    (fc): Linear(in_features=256, out_features=7708, bias=True)
  )
)
[2024-05-01 17:56:26] Epoch 1/45, train_loss: 4.145, val_bleu1: 0.530, val_bleu4: 0.104
[2024-05-01 17:58:14] Epoch 2/45, train_loss: 3.481, val_bleu1: 0.554, val_bleu4: 0.128
[2024-05-01 18:00:02] Epoch 3/45, train_loss: 3.262, val_bleu1: 0.607, val_bleu4: 0.162
[2024-05-01 18:01:51] Epoch 4/45, train_loss: 3.134, val_bleu1: 0.644, val_bleu4: 0.189
[2024-05-01 18:03:38] Epoch 5/45, train_loss: 3.053, val_bleu1: 0.564, val_bleu4: 0.153
[2024-05-01 18:05:27] Epoch 6/45, train_loss: 2.949, val_bleu1: 0.644, val_bleu4: 0.181
[2024-05-01 18:07:15] Epoch 7/45, train_loss: 2.933, val_bleu1: 0.571, val_bleu4: 0.155
[2024-05-01 18:09:04] Epoch 8/45, train_loss: 2.888, val_bleu1: 0.629, val_bleu4: 0.185
[2024-05-01 18:10:52] Epoch 9/45, train_loss: 2.868, val_bleu1: 0.612, val_bleu4: 0.176
[2024-05-01 18:12:41] Epoch 10/45, train_loss: 2.828, val_bleu1: 0.624, val_bleu4: 0.182
[2024-05-01 18:14:29] Epoch 11/45, train_loss: 2.814, val_bleu1: 0.621, val_bleu4: 0.183
[2024-05-01 18:16:18] Epoch 12/45, train_loss: 2.835, val_bleu1: 0.669, val_bleu4: 0.207
[2024-05-01 18:18:07] Epoch 13/45, train_loss: 2.834, val_bleu1: 0.609, val_bleu4: 0.172
[2024-05-01 18:19:55] Epoch 14/45, train_loss: 2.823, val_bleu1: 0.669, val_bleu4: 0.199
[2024-05-01 18:21:44] Epoch 15/45, train_loss: 2.834, val_bleu1: 0.691, val_bleu4: 0.213
[2024-05-01 18:23:33] Epoch 16/45, train_loss: 2.875, val_bleu1: 0.702, val_bleu4: 0.212
[2024-05-01 18:25:22] Epoch 17/45, train_loss: 2.851, val_bleu1: 0.661, val_bleu4: 0.190
[2024-05-01 18:27:10] Epoch 18/45, train_loss: 2.908, val_bleu1: 0.702, val_bleu4: 0.213
[2024-05-01 18:28:59] Epoch 19/45, train_loss: 2.947, val_bleu1: 0.704, val_bleu4: 0.223
[2024-05-01 18:30:48] Epoch 20/45, train_loss: 2.943, val_bleu1: 0.685, val_bleu4: 0.207
[2024-05-01 18:32:37] Epoch 21/45, train_loss: 3.004, val_bleu1: 0.706, val_bleu4: 0.223
[2024-05-01 18:34:25] Epoch 22/45, train_loss: 2.971, val_bleu1: 0.713, val_bleu4: 0.230
[2024-05-01 18:36:14] Epoch 23/45, train_loss: 3.031, val_bleu1: 0.711, val_bleu4: 0.216
[2024-05-01 18:38:02] Epoch 24/45, train_loss: 3.029, val_bleu1: 0.696, val_bleu4: 0.212
[2024-05-01 18:39:50] Epoch 25/45, train_loss: 3.093, val_bleu1: 0.699, val_bleu4: 0.212
[2024-05-01 18:41:39] Epoch 26/45, train_loss: 3.166, val_bleu1: 0.719, val_bleu4: 0.215
[2024-05-01 18:43:28] Epoch 27/45, train_loss: 3.149, val_bleu1: 0.701, val_bleu4: 0.208
[2024-05-01 18:45:16] Epoch 28/45, train_loss: 3.206, val_bleu1: 0.707, val_bleu4: 0.192
[2024-05-01 18:47:05] Epoch 29/45, train_loss: 3.218, val_bleu1: 0.698, val_bleu4: 0.196
[2024-05-01 18:48:53] Epoch 30/45, train_loss: 3.291, val_bleu1: 0.705, val_bleu4: 0.194
[2024-05-01 18:50:41] Epoch 31/45, train_loss: 3.307, val_bleu1: 0.703, val_bleu4: 0.188
[2024-05-01 18:52:30] Epoch 32/45, train_loss: 3.336, val_bleu1: 0.690, val_bleu4: 0.183
[2024-05-01 18:54:18] Epoch 33/45, train_loss: 3.369, val_bleu1: 0.689, val_bleu4: 0.172
[2024-05-01 18:56:07] Epoch 34/45, train_loss: 3.351, val_bleu1: 0.665, val_bleu4: 0.157
[2024-05-01 18:57:56] Epoch 35/45, train_loss: 3.397, val_bleu1: 0.672, val_bleu4: 0.161
[2024-05-01 18:59:45] Epoch 36/45, train_loss: 3.451, val_bleu1: 0.672, val_bleu4: 0.160
[2024-05-01 19:01:33] Epoch 37/45, train_loss: 3.452, val_bleu1: 0.644, val_bleu4: 0.146
[2024-05-01 19:03:22] Epoch 38/45, train_loss: 3.478, val_bleu1: 0.674, val_bleu4: 0.147
[2024-05-01 19:05:11] Epoch 39/45, train_loss: 3.452, val_bleu1: 0.656, val_bleu4: 0.143
[2024-05-01 19:07:00] Epoch 40/45, train_loss: 3.489, val_bleu1: 0.658, val_bleu4: 0.133
[2024-05-01 19:08:48] Epoch 41/45, train_loss: 3.491, val_bleu1: 0.638, val_bleu4: 0.124
[2024-05-01 19:10:39] Epoch 42/45, train_loss: 3.507, val_bleu1: 0.639, val_bleu4: 0.118
[2024-05-01 19:12:30] Epoch 43/45, train_loss: 3.518, val_bleu1: 0.639, val_bleu4: 0.119
[2024-05-01 19:14:21] Epoch 44/45, train_loss: 3.515, val_bleu1: 0.632, val_bleu4: 0.117
[2024-05-01 19:16:12] Epoch 45/45, train_loss: 3.529, val_bleu1: 0.634, val_bleu4: 0.111
[2024-05-01 19:17:10] evaluation of the best validation performance model: 
[2024-05-01 19:17:10] train
[2024-05-01 19:17:10] Bleu-1: 0.755
[2024-05-01 19:17:10] Bleu-2: 0.557
[2024-05-01 19:17:10] Bleu-3: 0.406
[2024-05-01 19:17:10] Bleu-4: 0.293
[2024-05-01 19:17:10] 
[2024-05-01 19:17:10] val
[2024-05-01 19:17:10] Bleu-1: 0.713
[2024-05-01 19:17:10] Bleu-2: 0.495
[2024-05-01 19:17:10] Bleu-3: 0.341
[2024-05-01 19:17:10] Bleu-4: 0.230
[2024-05-01 19:17:10] 
[2024-05-01 19:17:10] test
[2024-05-01 19:17:10] Bleu-1: 0.704
[2024-05-01 19:17:10] Bleu-2: 0.483
[2024-05-01 19:17:10] Bleu-3: 0.326
[2024-05-01 19:17:10] Bleu-4: 0.217
[2024-05-01 19:17:10] 
