[2024-05-01 02:52:25] Captioner(
  (encoder): Encoder(
    (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))
  )
  (decoder): DecoderWithAttention(
    (attention): Attention(
      (encoder_att): Linear(in_features=768, out_features=256, bias=True)
      (decoder_att): Linear(in_features=256, out_features=256, bias=True)
      (full_att): Linear(in_features=256, out_features=1, bias=True)
      (relu): ReLU()
      (softmax): Softmax(dim=1)
    )
    (embedding): Embedding(7708, 300)
    (dropout): Dropout(p=0.5, inplace=False)
    (decode_step): LSTMCell(1068, 256)
    (init_h): Linear(in_features=768, out_features=256, bias=True)
    (init_c): Linear(in_features=768, out_features=256, bias=True)
    (f_beta): Linear(in_features=256, out_features=768, bias=True)
    (sigmoid): Sigmoid()
    (fc): Linear(in_features=256, out_features=7708, bias=True)
  )
)
[2024-05-01 02:54:15] Epoch 1/45, train_loss: 4.002, val_bleu1: 0.559, val_bleu4: 0.114
[2024-05-01 02:56:05] Epoch 2/45, train_loss: 3.312, val_bleu1: 0.604, val_bleu4: 0.149
[2024-05-01 02:57:54] Epoch 3/45, train_loss: 3.097, val_bleu1: 0.583, val_bleu4: 0.154
[2024-05-01 02:59:43] Epoch 4/45, train_loss: 2.956, val_bleu1: 0.637, val_bleu4: 0.189
[2024-05-01 03:01:32] Epoch 5/45, train_loss: 2.875, val_bleu1: 0.552, val_bleu4: 0.152
[2024-05-01 03:03:22] Epoch 6/45, train_loss: 2.780, val_bleu1: 0.665, val_bleu4: 0.205
[2024-05-01 03:05:11] Epoch 7/45, train_loss: 2.735, val_bleu1: 0.585, val_bleu4: 0.163
[2024-05-01 03:07:00] Epoch 8/45, train_loss: 2.689, val_bleu1: 0.598, val_bleu4: 0.175
[2024-05-01 03:08:48] Epoch 9/45, train_loss: 2.656, val_bleu1: 0.629, val_bleu4: 0.192
[2024-05-01 03:10:37] Epoch 10/45, train_loss: 2.617, val_bleu1: 0.629, val_bleu4: 0.194
[2024-05-01 03:12:26] Epoch 11/45, train_loss: 2.598, val_bleu1: 0.649, val_bleu4: 0.194
[2024-05-01 03:14:14] Epoch 12/45, train_loss: 2.566, val_bleu1: 0.666, val_bleu4: 0.200
[2024-05-01 03:16:03] Epoch 13/45, train_loss: 2.554, val_bleu1: 0.609, val_bleu4: 0.183
[2024-05-01 03:17:51] Epoch 14/45, train_loss: 2.551, val_bleu1: 0.645, val_bleu4: 0.203
[2024-05-01 03:19:40] Epoch 15/45, train_loss: 2.515, val_bleu1: 0.677, val_bleu4: 0.219
[2024-05-01 03:21:28] Epoch 16/45, train_loss: 2.532, val_bleu1: 0.672, val_bleu4: 0.213
[2024-05-01 03:23:17] Epoch 17/45, train_loss: 2.503, val_bleu1: 0.639, val_bleu4: 0.188
[2024-05-01 03:25:06] Epoch 18/45, train_loss: 2.505, val_bleu1: 0.666, val_bleu4: 0.214
[2024-05-01 03:26:55] Epoch 19/45, train_loss: 2.509, val_bleu1: 0.649, val_bleu4: 0.205
[2024-05-01 03:28:44] Epoch 20/45, train_loss: 2.467, val_bleu1: 0.659, val_bleu4: 0.205
[2024-05-01 03:30:33] Epoch 21/45, train_loss: 2.498, val_bleu1: 0.690, val_bleu4: 0.228
[2024-05-01 03:32:22] Epoch 22/45, train_loss: 2.453, val_bleu1: 0.669, val_bleu4: 0.219
[2024-05-01 03:34:11] Epoch 23/45, train_loss: 2.476, val_bleu1: 0.687, val_bleu4: 0.219
[2024-05-01 03:36:00] Epoch 24/45, train_loss: 2.439, val_bleu1: 0.666, val_bleu4: 0.215
[2024-05-01 03:37:49] Epoch 25/45, train_loss: 2.473, val_bleu1: 0.675, val_bleu4: 0.216
[2024-05-01 03:39:37] Epoch 26/45, train_loss: 2.475, val_bleu1: 0.695, val_bleu4: 0.230
[2024-05-01 03:41:26] Epoch 27/45, train_loss: 2.454, val_bleu1: 0.667, val_bleu4: 0.213
[2024-05-01 03:43:15] Epoch 28/45, train_loss: 2.460, val_bleu1: 0.696, val_bleu4: 0.225
[2024-05-01 03:45:04] Epoch 29/45, train_loss: 2.459, val_bleu1: 0.671, val_bleu4: 0.219
[2024-05-01 03:46:53] Epoch 30/45, train_loss: 2.473, val_bleu1: 0.633, val_bleu4: 0.191
[2024-05-01 03:48:42] Epoch 31/45, train_loss: 2.490, val_bleu1: 0.680, val_bleu4: 0.207
[2024-05-01 03:50:31] Epoch 32/45, train_loss: 2.444, val_bleu1: 0.670, val_bleu4: 0.211
[2024-05-01 03:52:20] Epoch 33/45, train_loss: 2.476, val_bleu1: 0.688, val_bleu4: 0.216
[2024-05-01 03:54:08] Epoch 34/45, train_loss: 2.482, val_bleu1: 0.686, val_bleu4: 0.220
[2024-05-01 03:55:56] Epoch 35/45, train_loss: 2.520, val_bleu1: 0.688, val_bleu4: 0.216
[2024-05-01 03:57:45] Epoch 36/45, train_loss: 2.456, val_bleu1: 0.691, val_bleu4: 0.223
[2024-05-01 03:59:34] Epoch 37/45, train_loss: 2.486, val_bleu1: 0.693, val_bleu4: 0.228
[2024-05-01 04:01:22] Epoch 38/45, train_loss: 2.521, val_bleu1: 0.704, val_bleu4: 0.221
[2024-05-01 04:03:10] Epoch 39/45, train_loss: 2.496, val_bleu1: 0.655, val_bleu4: 0.197
[2024-05-01 04:04:59] Epoch 40/45, train_loss: 2.530, val_bleu1: 0.697, val_bleu4: 0.217
[2024-05-01 04:06:50] Epoch 41/45, train_loss: 2.497, val_bleu1: 0.686, val_bleu4: 0.217
[2024-05-01 04:08:39] Epoch 42/45, train_loss: 2.525, val_bleu1: 0.658, val_bleu4: 0.201
[2024-05-01 04:10:29] Epoch 43/45, train_loss: 2.531, val_bleu1: 0.702, val_bleu4: 0.231
[2024-05-01 04:12:18] Epoch 44/45, train_loss: 2.522, val_bleu1: 0.685, val_bleu4: 0.219
[2024-05-01 04:14:07] Epoch 45/45, train_loss: 2.563, val_bleu1: 0.699, val_bleu4: 0.216
[2024-05-01 04:15:05] evaluation of the best validation performance model: 
[2024-05-01 04:15:05] train
[2024-05-01 04:15:05] Bleu-1: 0.788
[2024-05-01 04:15:05] Bleu-2: 0.618
[2024-05-01 04:15:05] Bleu-3: 0.479
[2024-05-01 04:15:05] Bleu-4: 0.369
[2024-05-01 04:15:05] 
[2024-05-01 04:15:05] val
[2024-05-01 04:15:05] Bleu-1: 0.702
[2024-05-01 04:15:05] Bleu-2: 0.498
[2024-05-01 04:15:05] Bleu-3: 0.346
[2024-05-01 04:15:05] Bleu-4: 0.231
[2024-05-01 04:15:05] 
[2024-05-01 04:15:05] test
[2024-05-01 04:15:05] Bleu-1: 0.697
[2024-05-01 04:15:05] Bleu-2: 0.485
[2024-05-01 04:15:05] Bleu-3: 0.334
[2024-05-01 04:15:05] Bleu-4: 0.229
[2024-05-01 04:15:05] 
