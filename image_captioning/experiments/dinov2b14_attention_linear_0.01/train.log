[2024-04-30 21:00:57] Captioner(
  (encoder): Encoder(
    (adaptive_pool): AdaptiveAvgPool2d(output_size=(14, 14))
  )
  (decoder): DecoderWithAttention(
    (attention): Attention(
      (encoder_att): Linear(in_features=768, out_features=256, bias=True)
      (decoder_att): Linear(in_features=256, out_features=256, bias=True)
      (full_att): Linear(in_features=256, out_features=1, bias=True)
      (relu): ReLU()
      (softmax): Softmax(dim=1)
    )
    (embedding): Embedding(7708, 300)
    (dropout): Dropout(p=0.5, inplace=False)
    (decode_step): LSTMCell(1068, 256)
    (init_h): Linear(in_features=768, out_features=256, bias=True)
    (init_c): Linear(in_features=768, out_features=256, bias=True)
    (f_beta): Linear(in_features=256, out_features=768, bias=True)
    (sigmoid): Sigmoid()
    (fc): Linear(in_features=256, out_features=7708, bias=True)
  )
)
[2024-04-30 21:02:45] Epoch 1/45, train_loss: 4.002, val_bleu1: 0.559, val_bleu4: 0.114
[2024-04-30 21:04:33] Epoch 2/45, train_loss: 3.312, val_bleu1: 0.604, val_bleu4: 0.149
[2024-04-30 21:06:22] Epoch 3/45, train_loss: 3.098, val_bleu1: 0.570, val_bleu4: 0.151
[2024-04-30 21:08:11] Epoch 4/45, train_loss: 2.956, val_bleu1: 0.637, val_bleu4: 0.190
[2024-04-30 21:10:00] Epoch 5/45, train_loss: 2.877, val_bleu1: 0.528, val_bleu4: 0.144
[2024-04-30 21:11:49] Epoch 6/45, train_loss: 2.784, val_bleu1: 0.664, val_bleu4: 0.203
[2024-04-30 21:13:38] Epoch 7/45, train_loss: 2.737, val_bleu1: 0.598, val_bleu4: 0.168
[2024-04-30 21:15:27] Epoch 8/45, train_loss: 2.696, val_bleu1: 0.605, val_bleu4: 0.183
[2024-04-30 21:17:16] Epoch 9/45, train_loss: 2.664, val_bleu1: 0.621, val_bleu4: 0.188
[2024-04-30 21:19:03] Epoch 10/45, train_loss: 2.622, val_bleu1: 0.618, val_bleu4: 0.184
[2024-04-30 21:20:51] Epoch 11/45, train_loss: 2.602, val_bleu1: 0.656, val_bleu4: 0.198
[2024-04-30 21:22:40] Epoch 12/45, train_loss: 2.580, val_bleu1: 0.666, val_bleu4: 0.203
[2024-04-30 21:24:30] Epoch 13/45, train_loss: 2.565, val_bleu1: 0.612, val_bleu4: 0.179
[2024-04-30 21:26:18] Epoch 14/45, train_loss: 2.565, val_bleu1: 0.645, val_bleu4: 0.205
[2024-04-30 21:28:06] Epoch 15/45, train_loss: 2.536, val_bleu1: 0.683, val_bleu4: 0.226
[2024-04-30 21:29:55] Epoch 16/45, train_loss: 2.555, val_bleu1: 0.673, val_bleu4: 0.211
[2024-04-30 21:31:44] Epoch 17/45, train_loss: 2.517, val_bleu1: 0.641, val_bleu4: 0.192
[2024-04-30 21:33:32] Epoch 18/45, train_loss: 2.533, val_bleu1: 0.672, val_bleu4: 0.219
[2024-04-30 21:35:21] Epoch 19/45, train_loss: 2.540, val_bleu1: 0.652, val_bleu4: 0.204
[2024-04-30 21:37:09] Epoch 20/45, train_loss: 2.498, val_bleu1: 0.672, val_bleu4: 0.211
[2024-04-30 21:38:58] Epoch 21/45, train_loss: 2.529, val_bleu1: 0.685, val_bleu4: 0.220
[2024-04-30 21:40:47] Epoch 22/45, train_loss: 2.493, val_bleu1: 0.669, val_bleu4: 0.219
[2024-04-30 21:42:37] Epoch 23/45, train_loss: 2.518, val_bleu1: 0.688, val_bleu4: 0.214
[2024-04-30 21:44:26] Epoch 24/45, train_loss: 2.495, val_bleu1: 0.686, val_bleu4: 0.222
[2024-04-30 21:46:14] Epoch 25/45, train_loss: 2.530, val_bleu1: 0.663, val_bleu4: 0.204
[2024-04-30 21:48:04] Epoch 26/45, train_loss: 2.533, val_bleu1: 0.687, val_bleu4: 0.226
[2024-04-30 21:49:53] Epoch 27/45, train_loss: 2.523, val_bleu1: 0.663, val_bleu4: 0.205
[2024-04-30 21:51:41] Epoch 28/45, train_loss: 2.526, val_bleu1: 0.693, val_bleu4: 0.220
[2024-04-30 21:53:30] Epoch 29/45, train_loss: 2.532, val_bleu1: 0.690, val_bleu4: 0.220
[2024-04-30 21:55:19] Epoch 30/45, train_loss: 2.556, val_bleu1: 0.661, val_bleu4: 0.199
[2024-04-30 21:57:08] Epoch 31/45, train_loss: 2.578, val_bleu1: 0.693, val_bleu4: 0.208
[2024-04-30 21:58:57] Epoch 32/45, train_loss: 2.558, val_bleu1: 0.661, val_bleu4: 0.209
[2024-04-30 22:00:46] Epoch 33/45, train_loss: 2.577, val_bleu1: 0.707, val_bleu4: 0.224
[2024-04-30 22:02:35] Epoch 34/45, train_loss: 2.590, val_bleu1: 0.687, val_bleu4: 0.215
[2024-04-30 22:04:24] Epoch 35/45, train_loss: 2.628, val_bleu1: 0.702, val_bleu4: 0.215
[2024-04-30 22:06:13] Epoch 36/45, train_loss: 2.583, val_bleu1: 0.708, val_bleu4: 0.232
[2024-04-30 22:08:02] Epoch 37/45, train_loss: 2.607, val_bleu1: 0.699, val_bleu4: 0.220
[2024-04-30 22:09:51] Epoch 38/45, train_loss: 2.665, val_bleu1: 0.705, val_bleu4: 0.216
[2024-04-30 22:11:40] Epoch 39/45, train_loss: 2.625, val_bleu1: 0.684, val_bleu4: 0.209
[2024-04-30 22:13:29] Epoch 40/45, train_loss: 2.671, val_bleu1: 0.699, val_bleu4: 0.209
[2024-04-30 22:15:18] Epoch 41/45, train_loss: 2.648, val_bleu1: 0.692, val_bleu4: 0.219
[2024-04-30 22:17:07] Epoch 42/45, train_loss: 2.688, val_bleu1: 0.698, val_bleu4: 0.212
[2024-04-30 22:18:56] Epoch 43/45, train_loss: 2.714, val_bleu1: 0.712, val_bleu4: 0.222
[2024-04-30 22:20:46] Epoch 44/45, train_loss: 2.682, val_bleu1: 0.697, val_bleu4: 0.227
[2024-04-30 22:22:35] Epoch 45/45, train_loss: 2.733, val_bleu1: 0.709, val_bleu4: 0.216
[2024-04-30 22:23:33] evaluation of the best validation performance model: 
[2024-04-30 22:23:33] train
[2024-04-30 22:23:33] Bleu-1: 0.782
[2024-04-30 22:23:33] Bleu-2: 0.608
[2024-04-30 22:23:33] Bleu-3: 0.467
[2024-04-30 22:23:33] Bleu-4: 0.357
[2024-04-30 22:23:33] 
[2024-04-30 22:23:33] val
[2024-04-30 22:23:33] Bleu-1: 0.708
[2024-04-30 22:23:33] Bleu-2: 0.494
[2024-04-30 22:23:33] Bleu-3: 0.341
[2024-04-30 22:23:33] Bleu-4: 0.232
[2024-04-30 22:23:33] 
[2024-04-30 22:23:33] test
[2024-04-30 22:23:33] Bleu-1: 0.699
[2024-04-30 22:23:33] Bleu-2: 0.487
[2024-04-30 22:23:33] Bleu-3: 0.338
[2024-04-30 22:23:33] Bleu-4: 0.234
[2024-04-30 22:23:33] 
